@inproceedings{10.1145/3474085.3475201,
author = {Wu, Xiongwei and Fu, Xin and Liu, Ying and Lim, Ee-Peng and Hoi, Steven C.H. and Sun, Qianru},
title = {A Large-Scale Benchmark for Food Image Segmentation},
year = {2021},
isbn = {9781450386517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3474085.3475201},
doi = {10.1145/3474085.3475201},
abstract = {Food image segmentation is a critical and indispensible task for developing health-related applications such as estimating food calories and nutrients. Existing food image segmentation models are underperforming due to two reasons: (1) there is a lack of high quality food image datasets with fine-grained ingredient labels and pixel-wise location masks---the existing datasets either carry coarse ingredient labels or are small in size; and (2) the complex appearance of food makes it difficult to localize and recognize ingredients in food images, e.g., the ingredients may overlap one another in the same image, and the identical ingredient may appear distinctly in different food images.In this work, we build a new food image dataset FoodSeg103 (and its extension FoodSeg154) containing 9,490 images. We annotate these images with 154 ingredient classes and each image has an average of 6 ingredient labels and pixel-wise masks. In addition, we propose a multi-modality pre-training approach called ReLeM that explicitly equips a segmentation model with rich and semantic food knowledge. In experiments, we use three popular semantic segmentation methods (i.e., Dilated Convolution based[20], Feature Pyramid based[25], and Vision Transformer based[60] ) as baselines, and evaluate them as well as ReLeM on our new datasets. We believe that the FoodSeg103 (and its extension FoodSeg154) and the pre-trained models using ReLeM can serve as a benchmark to facilitate future works on fine-grained food image understanding. We make all these datasets and methods public at https://xiongweiwu.github.io/foodseg103.html.},
booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
pages = {506–515},
numpages = {10},
keywords = {deep learning, food computing, semantic segmentation, datasets},
location = {Virtual Event, China},
series = {MM '21}
}

@article{AKBULUT2018494,
	title = {An effective color texture image segmentation algorithm based on hermite transform},
	journal = {Applied Soft Computing},
	volume = {67},
	pages = {494-504},
	year = {2018},
	issn = {1568-4946},
	doi = {https://doi.org/10.1016/j.asoc.2018.03.018},
	url = {https://www.sciencedirect.com/science/article/pii/S1568494618301406},
	author = {Yaman Akbulut and Yanhui Guo and Abdulkadir Şengür and Muzaffer Aslan},
	keywords = {Color texture image segmentation, Hermite transform, Edge preserving filtering, Mean shift clustering},
	abstract = {In this paper, an efficient color texture image segmentation approach is proposed. The proposed approach uses color and texture information independently. The color information is obtained by converting the RGB color space to Luv color space and each color component is considered as a color descriptor. For texture descriptors, Hermite transform is considered. Hermite transform uses the Hermite filters which are formed by the product of Hermite polynomials with Gaussian function. Instead of using all Hermite filters, a filter selection process is adopted to obtain optimal filters. A feature image is constructed based on the magnitude of each filter response. A region smoothing procedure is employed for both the color components and the feature image in order to make the region smoother while preserving the edge information. To this end, weighted least square edge-preserving filtering is used. Comprehensive experiments were conducted to demonstrate the efficiency of the proposed method, using the Berkeley segmentation dataset.}
}

@INPROCEEDINGS{8987480,
	author={Akmal and Munir, Rinaldi and Santoso, Judhi},
	booktitle={2019 5th International Conference on Science in Information Technology (ICSITech)}, 
	title={Image Graph Matching Based on Region Adjacency Graph}, 
	year={2019},
	volume={},
	number={},
	pages={176-181},
	keywords={segmentation;graph extraction;region adjacency graph;exact graph matching;inexact graph matching},	
	doi={10.1109/ICSITech46713.2019.8987480}
}

@ARTICLE{6205760,
	author={Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and Süsstrunk, Sabine},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={SLIC Superpixels Compared to State-of-the-Art Superpixel Methods}, 
	year={2012},
	volume={34},
	number={11},
	pages={2274-2282},
	keywords={Clustering algorithms;Image segmentation;Complexity theory;Image color analysis;Image edge detection;Measurement uncertainty;Approximation algorithms;Superpixels;segmentation;clustering;k-means},
	doi={10.1109/TPAMI.2012.120}
}

@ARTICLE{841950,
	author={Tremeau, A. and Colantoni, P.},
	journal={IEEE Transactions on Image Processing}, 
	title={Regions adjacency graph applied to color image segmentation}, 
	year={2000},
	volume={9},
	number={4},
	pages={735-744},
	keywords={Image segmentation;Image color analysis;Clustering algorithms;Iterative algorithms;Region 8;Large Hadron Collider;Automatic testing;Robustness;Algorithm design and analysis},
	doi={10.1109/83.841950}
}

@ARTICLE{868688,
	author={Jianbo Shi and Malik, J.},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
	title={Normalized cuts and image segmentation}, 
	year={2000},
	volume={22},
	number={8},
	pages={888-905},
	keywords={Image segmentation;Brightness;Clustering algorithms;Data mining;Eigenvalues and eigenfunctions;Bayesian methods;Coherence;Tree data structures;Filling;Partitioning algorithms},
	doi={10.1109/34.868688}
}

@misc{chollet2015keras,
	title={Keras},
	author={Chollet, Fran\c{c}ois and others},
	year={2015},
	howpublished={\url{https://keras.io}},
}

@misc{tensorflow2015-whitepaper,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dandelion~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}

@Article{         harris2020array,
	title         = {Array programming with {NumPy}},
	author        = {Charles R. Harris and K. Jarrod Millman and St{\'{e}}fan J.
	van der Walt and Ralf Gommers and Pauli Virtanen and David
	Cournapeau and Eric Wieser and Julian Taylor and Sebastian
	Berg and Nathaniel J. Smith and Robert Kern and Matti Picus
	and Stephan Hoyer and Marten H. van Kerkwijk and Matthew
	Brett and Allan Haldane and Jaime Fern{\'{a}}ndez del
	R{\'{i}}o and Mark Wiebe and Pearu Peterson and Pierre
	G{\'{e}}rard-Marchant and Kevin Sheppard and Tyler Reddy and
	Warren Weckesser and Hameer Abbasi and Christoph Gohlke and
	Travis E. Oliphant},
	year          = {2020},
	month         = sep,
	journal       = {Nature},
	volume        = {585},
	number        = {7825},
	pages         = {357--362},
	doi           = {10.1038/s41586-020-2649-2},
	publisher     = {Springer Science and Business Media {LLC}},
	url           = {https://doi.org/10.1038/s41586-020-2649-2}
}

@article{scikit-image,
	title = {scikit-image: image processing in {P}ython},
	author = {van der Walt, {S}t\'efan and {S}ch\"onberger, {J}ohannes {L}. and
	{Nunez-Iglesias}, {J}uan and {B}oulogne, {F}ran\c{c}ois and {W}arner,
	{J}oshua {D}. and {Y}ager, {N}eil and {G}ouillart, {E}mmanuelle and
	{Y}u, {T}ony and the scikit-image contributors},
	year = {2014},
	month = {6},
	keywords = {Image processing, Reproducible research, Education,
	Visualization, Open source, Python, Scientific programming},
	volume = {2},
	pages = {e453},
	journal = {PeerJ},
	issn = {2167-8359},
	url = {https://doi.org/10.7717/peerj.453},
	doi = {10.7717/peerj.453}
}

@Article{Hunter:2007,
	Author    = {Hunter, J. D.},
	Title     = {Matplotlib: A 2D graphics environment},
	Journal   = {Computing in Science \& Engineering},
	Volume    = {9},
	Number    = {3},
	Pages     = {90--95},
	abstract  = {Matplotlib is a 2D graphics package used for Python for
	application development, interactive scripting, and publication-quality
	image generation across user interfaces and operating systems.},
	publisher = {IEEE COMPUTER SOC},
	doi       = {10.1109/MCSE.2007.55},
	year      = 2007
}

